{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、背景\n",
    "\n",
    "##### 1.1、数值微分计算梯度有什么问题？\n",
    "\n",
    "- 费时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二、计算图\n",
    "\n",
    "##### 2.1、实际问题建模为计算图表示的过程\n",
    "\n",
    "- 在超市买了 2 个苹果、3 个橘子。其中，苹果每个 100 元，橘子每个 150 元。消费税是 10%，请计算支付金额。\n",
    "\n",
    "- ![](./attachements/基于计算图的建模过程.png)\n",
    "- ![](./attachements/反向传播计算实例.png)\n",
    "\n",
    "##### 2.2、正向传播与反向传播传播的是什么？\n",
    "- 正向传播：传播的是激活值（中间计算结果）\n",
    "- 反向传播：传播的是梯度信息（损失对每个节点的梯度）\n",
    "\n",
    "\n",
    "##### 2.3、为什么要使用计算图？\n",
    "- 使用计算图最大的原因是，可以通过反向传播高效计算导数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三、链式法则\n",
    "\n",
    "\n",
    "##### 3.1、什么是链式法则？\n",
    "\n",
    "- 定义：如果某个函数由复合函数表示，则该复合函数的导数可以用构成复合函数的各个函数的导数的乘积表示。\n",
    "- 实例：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z = t^2 \\\\\n",
    "t = x + y\n",
    "\\end{align*}\n",
    "\n",
    "\\longrightarrow \n",
    "\n",
    "\\frac{\\partial z}{\\partial x}=\\frac{\\partial z}{{\\color{Red} \\partial t} } \\frac{{\\color{Red} \\partial t} }{\\partial x}\n",
    "\n",
    "\\longrightarrow \n",
    "\n",
    "=2t \\cdot 1 = 2(x + y)\n",
    "$$\n",
    "\n",
    "##### 3.2、链式法则在计算图中怎么实现反向传播的？\n",
    "\n",
    "- 沿着与正方向相反的方向，乘上局部导数后传递\n",
    "![](./attachements/反向传播在计算图中沿着与正方向相反的方向乘上局部导数后传递-上.png)\n",
    "![](./attachements/反向传播在计算图中沿着与正方向相反的方向乘上局部导数后传递-下.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 四、反向传播\n",
    "\n",
    "##### 4.1、MulLayer乘法层实现原理\n",
    "\n",
    "$$\n",
    "z = xy \n",
    "\n",
    "\\longrightarrow \n",
    "\n",
    "\\left\\{\\begin{matrix}\n",
    "  \\frac{\\partial z}{\\partial x}  = y& \\\\\n",
    "  \\frac{\\partial z}{\\partial y}  = x&\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "![](./attachements/乘法节点的正反向传播.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "class MulLayer:\n",
    "    def __init__(self) -> None:\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        out = x * y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.y \n",
    "        dy = dout * self.x\n",
    "\n",
    "        return dx, dy\n",
    "    \n",
    "\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "final_price = mul_tax_layer.forward(apple_price, tax)\n",
    "\n",
    "print(final_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 4.2、AddLayer加法层实现原理\n",
    "\n",
    "$$\n",
    "z = x + y \n",
    "\n",
    "\\longrightarrow \n",
    "\n",
    "\\left\\{\\begin{matrix}\n",
    "  \\frac{\\partial z}{\\partial x}  = 1& \\\\\n",
    "  \\frac{\\partial z}{\\partial y}  = 1&\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "![](./attachements/加法节点的正反向传播.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### 4.3、购买2个苹果+3个橘子的计算图与代码实现\n",
    "\n",
    "![](./attachements/反向传播计算实例.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "3.3000000000000003 165.0 2.2 110.00000000000001 1.1 1.1 1.1 650\n"
     ]
    }
   ],
   "source": [
    "# 我发现图形化编程特别适合我\n",
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "# 每一个节点就是一个计算Layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tex_layer = MulLayer()\n",
    "\n",
    "\n",
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange, orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n",
    "price = mul_tax_layer.forward(all_price, tax)\n",
    "\n",
    "\n",
    "#backward\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "\n",
    "print(price)\n",
    "print(dorange, dorange_num, dapple, dapple_num, dapple_price, dorange_price,  dall_price, dtax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4、激活函数层的计算图与代码实现\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = \\left\\{\\begin{matrix}\n",
    "  x&(x > 0) \\\\\n",
    "  0&(x \\le 0)\n",
    "\\end{matrix}\\right.\n",
    "\n",
    "\\longrightarrow \n",
    "\n",
    "\\frac{\\partial y}{\\partial x} = \\left\\{\\begin{matrix}\n",
    "  1&(x > 0) \\\\\n",
    "  0&(x \\le 0)\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "![](./attachements/ReLU层的计算图.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  -0.5]\n",
      " [-2.   3. ]]\n",
      "[[False  True]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "# ReLU层\n",
    "class ReLU:\n",
    "    def __init__(self) -> None:\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0 )\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx\n",
    "\n",
    "import numpy as np\n",
    "x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n",
    "print(x)\n",
    "mask = (x <= 0)\n",
    "print(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma(x)  = \\frac{1}{1 + exp(-x)} = \\frac{1}{1 + e^{-x}}  \n",
    "\n",
    "\\longrightarrow \n",
    "\n",
    "\\sigma'(x) = \\sigma(x) \\cdot (1 - \\sigma(x))\n",
    "$$\n",
    "\n",
    "![](./attachements/sigmoid层的计算图.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid层\n",
    "class Sigmoid:\n",
    "    def __init__(self) -> None:\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "\n",
    "        return dx\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5、神经网络正向传播中进行的矩阵乘积运算层-Affine仿射变换\n",
    "> 几何中，仿射变换包括一次线性变换和一次平移，分别对应神经网络的加权和运算与加偏置运算。\n",
    "\n",
    "$$\n",
    "\\boldsymbol{Y} = \\boldsymbol{X} \\cdot \\boldsymbol{W} + \\boldsymbol{B} \\\\\n",
    "\\frac{\\partial L}{\\partial \\boldsymbol{Y}} \\\\\n",
    "\\left\\{\\begin{matrix}\n",
    "  \\frac{\\partial L}{\\partial \\boldsymbol{X}} =  \\frac{\\partial L}{\\partial \\boldsymbol{Y}} \\cdot \\boldsymbol{W}^T \\\\\n",
    "  \\frac{\\partial L}{\\partial \\boldsymbol{W}} = \\boldsymbol{X}^T \\cdot \\frac{\\partial L}{\\partial \\boldsymbol{Y}}\n",
    "\\end{matrix}\\right.\n",
    "$$\n",
    "\n",
    "![](./attachements/Affine层的反向传播.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6、批版本的Affine仿射变换层计算图\n",
    "\n",
    "![](./attachements/批版本的Affine层计算图.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine层的实现\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self) -> None:\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "\n",
    "        return dx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 4.7、Softmax-with-Loss层的计算图与代码实现\n",
    "![](./attachements/Softmax-with-Loss层的计算图.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SoftmaxWithLoss\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_x = np.exp(x - c)  # 数值稳定性\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size \n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 损失\n",
    "        self.y = None # softmax 的输出\n",
    "        self.t = None # 监督数据（one-hot vector）\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 五、误差反向传播算法\n",
    "\n",
    "##### 5.1、神经网络学习全貌图\n",
    "\n",
    "- Step-01: （mini-batch）从训练数据中选择一部分数据\n",
    "- Step-02: （计算梯度）计算损失函数关于各个权重参数的梯度\n",
    "- Step-03: （更新参数）将权重参数沿梯度方向进行微小的更新\n",
    "- Step-04: （重复）重复步骤1、2、3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2、具备误差反向传播算法的神经网络实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11705 0.1154\n",
      "0.9051666666666667 0.9094\n",
      "0.9243166666666667 0.9265\n",
      "0.9382833333333334 0.9381\n",
      "0.9474 0.9467\n",
      "0.9538 0.9526\n",
      "0.9592166666666667 0.9578\n",
      "0.9624 0.9592\n",
      "0.9654833333333334 0.9621\n",
      "0.9675166666666667 0.963\n",
      "0.97125 0.9666\n",
      "0.9738166666666667 0.9695\n",
      "0.9747333333333333 0.9682\n",
      "0.9771666666666666 0.9711\n",
      "0.9783 0.9717\n",
      "0.9791833333333333 0.9722\n",
      "0.9800333333333333 0.9728\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import numpy as np\n",
    "from NeuralNetwork.Datasets.minist import load_mnist\n",
    "from NeuralNetwork.BackwardPropagation.TwoLayerNet import TwoLayerNet\n",
    "\n",
    "# 读入数据\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 梯度\n",
    "    # grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "\n",
    "    # 更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1NLP-1CODE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
